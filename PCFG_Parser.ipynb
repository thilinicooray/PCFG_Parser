{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCFGParser\n",
      "===========\n",
      "Sample sentences can be found in data/samples.txt \n",
      "\n",
      "Type input sentence : Each student came to the Hospital\n",
      "Parsed results for input : Each student came to the Hospital\n",
      "\n",
      "Parse Tree\n",
      "===========\n",
      "( S( NP( DT Each )( NN student ) )( VP( VBD came )( PP( IN to )( NP( DT the )( NN Hospital ) ) ) ) )\n",
      "\n",
      "CYK Chart \n",
      "==========\n",
      "chart index:00 \n",
      "\tDT->Each weight:-4.54965747606 indecies of rhs origin :0 0\n",
      "chart index:01 \n",
      "\tNP->DT NN weight:-11.55182322953 indecies of rhs origin :0 0,1 1\n",
      "chart index:02 \n",
      "chart index:03 \n",
      "chart index:04 \n",
      "chart index:05 \n",
      "\tNP->NP VP weight:-34.248606242653395 indecies of rhs origin :0 1,2 5\n",
      "\tFRAG->NP VP weight:-30.477123260003395 indecies of rhs origin :0 1,2 5\n",
      "\tS->NP VP weight:-28.285393201981034 indecies of rhs origin :0 1,2 5\n",
      "chart index:11 \n",
      "\tNN->student weight:-5.71867108715 indecies of rhs origin :1 1\n",
      "chart index:12 \n",
      "chart index:13 \n",
      "chart index:14 \n",
      "chart index:15 \n",
      "chart index:22 \n",
      "\tVBD->came weight:-4.1666652238 indecies of rhs origin :2 2\n",
      "chart index:23 \n",
      "chart index:24 \n",
      "chart index:25 \n",
      "\tVP->VBD PP weight:-16.728075453133396 indecies of rhs origin :2 2,3 5\n",
      "chart index:33 \n",
      "\tIN->to weight:-1.99353819804 indecies of rhs origin :3 3\n",
      "chart index:34 \n",
      "chart index:35 \n",
      "\tPP->IN NP weight:-10.149262933823398 indecies of rhs origin :3 3,4 5\n",
      "chart index:44 \n",
      "\tDT->the weight:-1.12214278608 indecies of rhs origin :4 4\n",
      "chart index:45 \n",
      "\tNP->DT NN weight:-8.124308539549999 indecies of rhs origin :4 4,5 5\n",
      "chart index:55 \n",
      "\tNN->Hospital weight:-5.71867108715 indecies of rhs origin :5 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# This class is to read grammar rules from the file and make the grammar \n",
    "\n",
    "class GrammarReader:\n",
    "    # initialize the parser by adding PCF grammar rules\n",
    "    # logarithm of the probabilities have been given in this file\n",
    "    def __init__ (self, rules='data/weighted.rule'):\n",
    "        self.grammar = self.readGrammar(rules)\n",
    "\n",
    "    # Given a file containing weighted rules, grammarFile, return a dictionary of\n",
    "    # those rules.\n",
    "    def readGrammar (self, grammarFile):\n",
    "        grammar = {}\n",
    "        rules = open(grammarFile, 'r')\n",
    "    \n",
    "        for rule in rules:\n",
    "            tmp = rule.split()\n",
    "            lhs = tmp[0]\n",
    "            rhs = ' '.join(tmp[1:-1])\n",
    "            weight = float(tmp[-1])\n",
    "\n",
    "            if lhs in grammar:\n",
    "                grammar[lhs][rhs] = weight\n",
    "            else:\n",
    "                grammar[lhs] = {rhs: weight}\n",
    "\n",
    "        rules.close()\n",
    "\n",
    "        return grammar\n",
    "    \n",
    "# This class is the basic building block for creating CYK chart \n",
    "\n",
    "class ChartElement:\n",
    "    def __init__ (self, *args, **kwargs):\n",
    "        self.ruleList = kwargs.get('ruleList', None)\n",
    "        \n",
    "        if self.ruleList is None:\n",
    "            \n",
    "            self.grammar = kwargs.get('grammar')\n",
    "            self.ruleList = RuleList()\n",
    "        \n",
    "            if (kwargs.get('isLexicon')):\n",
    "                \n",
    "                self.ruleList = self.initTerminal(kwargs.get('element1'), kwargs.get('index1'))\n",
    "            else :\n",
    "                self.ruleList = self.initNonterminal(kwargs.get('element1'), kwargs.get('element2'),kwargs.get('index1'), kwargs.get('index2'))\n",
    "        \n",
    "    def initTerminal (self, input, index):\n",
    "        #search through grammar[:][input]\n",
    "        # get all matching lhs, weights\n",
    "        #for all matching rules, create rules, origin = '0 0'\n",
    "        \n",
    "        lexiconRules = self.findMatchingRules(input, True, 0.0, str(index)+' '+ str(index))\n",
    "        # then look again for lhs of these rules and check whether they can be unary rules\n",
    "        # add new unary rules also to the list\n",
    "        for lexiconRule in lexiconRules:\n",
    "            matchingUnaryRules = self.findMatchingRules(lexiconRule.lhs, False, lexiconRule.weight, lexiconRule.origin)\n",
    "            lexiconRules.extend(matchingUnaryRules)\n",
    "        return lexiconRules\n",
    "        \n",
    "    def initNonterminal (self, lhsRules, rhsRules, index1, index2):\n",
    "        nonTerminalRules = RuleList()\n",
    "        # get lhs.lhs list and rhs.lhs list\n",
    "        # look for binary rules which can be made from those\n",
    "        for lhs_lhs in lhsRules:\n",
    "            for rhs_lhs in rhsRules:\n",
    "                binary_rhs = lhs_lhs.lhs + ' ' + rhs_lhs.lhs\n",
    "                \n",
    "                nonTerminalRules.extend(self.findMatchingRules(binary_rhs, False, lhs_lhs.weight + rhs_lhs.weight, index1 + ',' + index2 ))\n",
    "        # then look again for lhs of these rules and check whether they can be unary rules\n",
    "        \n",
    "        for nonTerminalRule in nonTerminalRules:\n",
    "            matchingUnaryRules = self.findMatchingRules(nonTerminalRule.lhs, False, nonTerminalRule.weight, nonTerminalRule.origin)\n",
    "            nonTerminalRules.extend(matchingUnaryRules)\n",
    "        # add new unary rules also to the list\n",
    "        \n",
    "        return nonTerminalRules\n",
    "        \n",
    "    def findMatchingRules (self, rhs, isLexicon, prob, origin):\n",
    "        \n",
    "        resultRules = RuleList()\n",
    "        for (lhs, d) in self.grammar.items():\n",
    "            for current_rhs in d:\n",
    "                if current_rhs == rhs:\n",
    "                    rule = Rule(lhs, rhs, prob + d[current_rhs],origin, isLexicon)\n",
    "                    resultRules.append(rule)\n",
    "\n",
    "        # Handle unseen words\n",
    "        if isLexicon and not resultRules:\n",
    "            print('Unknown word is found : ' + rhs)\n",
    "            sys.exit()\n",
    "\n",
    "        return resultRules\n",
    "\n",
    "# This class is inherited from default Python list in order to override append and extend methods\n",
    "# These methods were extended as we only need to keep the highest probabilistic among language rules with same LHS\n",
    "    \n",
    "class RuleList(list):\n",
    "    def append(self, newRule):\n",
    "        isNew = True\n",
    "        for currentRule in self:\n",
    "            if currentRule.lhs == newRule.lhs:\n",
    "                isNew = False\n",
    "                if currentRule.weight < newRule.weight:\n",
    "                    currentRule.rhs = newRule.rhs\n",
    "                    currentRule.weight = newRule.weight\n",
    "                    currentRule.origin = newRule.origin\n",
    "                    currentRule.isLexicon = newRule.isLexicon\n",
    "                break\n",
    "        if isNew:\n",
    "            super(RuleList, self).append(newRule)        \n",
    "        \n",
    "    def extend(self, newRules):\n",
    "        for newRule in newRules:\n",
    "            self.append(newRule)\n",
    "    \n",
    "# This class is to store details of all the rules separately\n",
    "class Rule:\n",
    "    def __init__(self, lhs, rhs, weight, origin, isLexicon):\n",
    "        self.lhs = lhs\n",
    "        self.rhs = rhs\n",
    "        self.weight = weight\n",
    "        self.origin = origin\n",
    "        self.isLexicon = isLexicon\n",
    "    \n",
    "# CYK Algorithm\n",
    "\n",
    "class CYKAlgo:\n",
    "    def __init__ (self, input, grammar):\n",
    "        self.input = input.split()\n",
    "        inputSize = len(self.input)\n",
    "        self.grammar = grammar\n",
    "        self.chart = np.empty(shape=(inputSize,inputSize), dtype=object)\n",
    "        self.parse(0, inputSize-1)\n",
    "     \n",
    "    # A dynamic program based parsing logic\n",
    "    # if index1 == index2, chart[index1][index2] = logic for parsing lexicon\n",
    "    # else chart[index1][index2] = max(index1<= k < index2)[parse(index1,k)+parse(k+1,index2)]\n",
    "    def parse (self, index1, index2):\n",
    "        if self.chart[index1,index2] is not None and len(self.chart[index1,index2].ruleList) != 0 :\n",
    "            return self.chart[index1,index2]\n",
    "        if index1 == index2:\n",
    "            self.chart[index1,index1] = ChartElement(index1=index1, element1=self.input[index1], grammar=self.grammar, isLexicon=True)\n",
    "            \n",
    "            return self.chart[index1,index1]\n",
    "        else :\n",
    "            maxProbRules = RuleList()\n",
    "            \n",
    "            for k in range(index1,index2):\n",
    "                \n",
    "                lhs = self.parse(index1, k).ruleList\n",
    "                \n",
    "                rhs = self.parse(k+1, index2).ruleList\n",
    "                \n",
    "                if(len(lhs) != 0 and len(rhs) != 0) :\n",
    "                    \n",
    "                    currentRules = ChartElement(index1=str(index1) +' '+ str(k), index2=str(k+1)+' '+ str(index2), element1=lhs, element2=rhs, grammar=self.grammar, isLexicon=False).ruleList\n",
    "                \n",
    "                    for rule in currentRules:\n",
    "                        maxProbRules.append(rule)\n",
    "                    \n",
    "            self.chart[index1,index2] = ChartElement(ruleList=maxProbRules)\n",
    "            return self.chart[index1,index2]\n",
    "\n",
    "#=================== Enf of class definitions ========================================       \n",
    "\n",
    "# Main method of the program\n",
    "def main():\n",
    "    defaultsInputSentence = 'good father gone for Market place'\n",
    "    inputSentence =''\n",
    "    #Get user input \n",
    "    print ('PCFGParser\\n===========')\n",
    "    print('Sample sentences can be found in data/samples.txt \\n')\n",
    "    userInputSent = input('Type input sentence : ')\n",
    "    if len(userInputSent) > 0:\n",
    "        inputSentence = userInputSent\n",
    "    else:\n",
    "        inputSentence = defaultsInputSentence\n",
    "    \n",
    "    print('Parsed results for input : ' + inputSentence + '\\n')\n",
    "    parseTreeChart = CYKAlgo(inputSentence, GrammarReader().grammar).chart\n",
    "    printParseTree(parseTreeChart)\n",
    "        \n",
    "def printParseTree (chart):\n",
    "    inputLen = chart.shape[0]\n",
    "    \n",
    "    #print parse tree\n",
    "    # look at the rules in chart[0][inputLen-1]\n",
    "    # if it is not empty, get the rule with the highest probability\n",
    "    #look at its origin and recursively print the rules until you meet origin x,x\n",
    "    #if such thing seen, check whether you can expand to more unary rules in same element\n",
    "    # else finish\n",
    "    \n",
    "    rootElement = chart[0][inputLen-1]\n",
    "    \n",
    "    if rootElement is not None and len(rootElement.ruleList) != 0:\n",
    "        maxProbRootRule = None\n",
    "        maxProb = float('-inf')\n",
    "        for rule in rootElement.ruleList:\n",
    "            if rule.weight > maxProb:\n",
    "                maxProb = rule.weight\n",
    "                maxProbRootRule = rule\n",
    "        print('Parse Tree\\n===========')\n",
    "        printRule(maxProbRootRule, chart)\n",
    "        print('\\n')\n",
    "        print('CYK Chart \\n==========')\n",
    "        printCYKChart(chart)\n",
    "            \n",
    "        \n",
    "    else :\n",
    "        print('No complete parse tree was found! \\n Following is the final CYK chart')\n",
    "        printCYKChart(chart)\n",
    "                            \n",
    "def printRule(rule, chart):\n",
    "    # look for origins of current element's rhs\n",
    "    originRules = None\n",
    "    if not rule.isLexicon:\n",
    "        originRules = getOriginRules(rule, chart)\n",
    "    print('( ' + rule.lhs, sep=' ', end='', flush=True)\n",
    "    if originRules:\n",
    "        for origin in originRules:\n",
    "            printRule(origin, chart) \n",
    "    else :\n",
    "        print(' ' + rule.rhs, sep=' ', end='', flush=True)\n",
    "    print(' )', sep=' ', end='', flush=True)\n",
    "    \n",
    "def getOriginRules (rule, chart):\n",
    "    rhsElements = rule.rhs.split()\n",
    "    originrhs = rule.origin.split(',')\n",
    "    originRules = []\n",
    "    for index in range(0, len(rhsElements)):\n",
    "        originElementIndex = originrhs[index].split()\n",
    "        originChartElement = chart[int(originElementIndex[0])][int(originElementIndex[1])]\n",
    "        \n",
    "        for rule in originChartElement.ruleList:\n",
    "            if (rule.lhs == rhsElements[index]):\n",
    "                originRules.append(rule)\n",
    "    return originRules     \n",
    "\n",
    "def printCYKChart(chart):\n",
    "    inputLen = chart.shape[0]\n",
    "    for i in range (0, inputLen):\n",
    "            for j in range (0, inputLen):\n",
    "                if chart[i][j] is not None:\n",
    "                    print('chart index:'+str(i)+str(j)+' ')\n",
    "                    if len(chart[i][j].ruleList) != 0:\n",
    "                        for rule in chart[i][j].ruleList:\n",
    "                            print('\\t' + rule.lhs + '->' + rule.rhs + ' weight:' + str(rule.weight) + ' indecies of rhs origin :'+rule.origin)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
